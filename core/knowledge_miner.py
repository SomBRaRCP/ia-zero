# core/knowledge_miner.py
"""
Minerador de Conhecimento Estrutural usando DeepSeek-Coder-V2-Lite (local)
Pipeline: ExtraÃ§Ã£o â†’ Quarentena â†’ ValidaÃ§Ã£o â†’ Colapso no Grafo TRQ

DeepSeek-Coder = microscÃ³pio (nÃ£o cÃ©rebro)
Grafo TRQ = lÃ¢mina
Antonia (RWKV) = voz

Modelo: deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct (16B)
"""
import json
import os
from pathlib import Path
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class CandidatoRelacao:
    """Candidato a relaÃ§Ã£o extraÃ­do por DeepSeek (zona de quarentena)"""
    de: str
    para: str
    tipo: str
    confianca: float
    contexto: str
    evidencia: str = ""
    origem: str = "deepseek"
    timestamp: str = ""

class KnowledgeMiner:
    """
    Minerador estrutural de conhecimento.
    
    IMPORTANTE: Este mÃ³dulo NÃƒO adiciona nada automaticamente ao grafo.
    Ele apenas gera candidatos para validaÃ§Ã£o humana.
    """
    
    def __init__(self, quarantine_path: str = "./data/quarentena", model_path: Optional[str] = None):
        self.quarantine_path = Path(quarantine_path)
        self.quarantine_path.mkdir(parents=True, exist_ok=True)
        
        # Configurar modelo local
        self.model: Optional[Any] = None
        self.tokenizer: Optional[Any] = None
        
        if model_path is None:
            model_path = "./models/deepseek-coder-v2-lite"
        
        self.model_path = Path(model_path)
        
        if self.model_path.exists():
            print(f"âœ… Modelo encontrado em: {self.model_path}")
            print("   (Modelo serÃ¡ carregado na primeira extraÃ§Ã£o)")
        else:
            print(f"âš ï¸  Modelo nÃ£o encontrado em: {self.model_path}")
            print("   Execute: python download_deepseek_model.py")
            print("   (Usando modo mock por enquanto)")
        
    def _load_model(self):
        """Carrega o modelo local (lazy loading)."""
        if self.model is not None:
            return  # JÃ¡ carregado
        
        if not self.model_path.exists():
            print("   âŒ Modelo nÃ£o encontrado. Use modo mock.")
            return
        
        try:
            from transformers import AutoTokenizer, AutoModelForCausalLM
            import torch
            
            print("   ğŸ”„ Carregando DeepSeek-Coder-V2-Lite...")
            
            self.tokenizer = AutoTokenizer.from_pretrained(
                str(self.model_path),
                trust_remote_code=True
            )
            
            device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"   ğŸ“ Dispositivo: {device}")
            
            self.model = AutoModelForCausalLM.from_pretrained(
                str(self.model_path),
                trust_remote_code=True,
                torch_dtype=torch.bfloat16 if device == "cuda" else torch.float32,
                device_map="auto" if device == "cuda" else None,
                low_cpu_mem_usage=True
            )
            
            print("   âœ… Modelo carregado!")
            
        except ImportError:
            print("   âŒ Bibliotecas faltando. Instale: pip install transformers torch accelerate")
        except Exception as e:
            print(f"   âŒ Erro ao carregar modelo: {e}")
    
    def extract_candidates(
        self,
        conceito_raiz: str,
        contexto: str = "geral",
        max_relacoes: int = 5
    ) -> List[CandidatoRelacao]:
        """
        Extrai candidatos a relaÃ§Ãµes usando DeepSeek-V3.
        
        Args:
            conceito_raiz: Conceito central para explorar
            contexto: Campo semÃ¢ntico (fisica, biologia, filosofia, etc)
            max_relacoes: MÃ¡ximo de relaÃ§Ãµes a extrair
        
        Returns:
            Lista de candidatos (NÃƒO adicionados ao grafo)
        """
        print(f"ğŸ”¬ Minerando relaÃ§Ãµes para '{conceito_raiz}' no campo '{contexto}'...")
        
        # Carrega modelo se necessÃ¡rio (lazy loading)
        if self.model is None and self.model_path.exists():
            self._load_model()
        
        if self.model is not None:
            candidatos = self._extract_with_local_model(conceito_raiz, contexto, max_relacoes)
        else:
            print("   âš ï¸  Modelo nÃ£o disponÃ­vel, usando mock")
            candidatos = self._extract_mock(conceito_raiz, contexto)
        
        # Salva na zona de quarentena
        self._save_to_quarantine(conceito_raiz, candidatos)
        
        print(f"   ExtraÃ­dos {len(candidatos)} candidatos â†’ quarentena")
        return candidatos
    
    def _extract_with_local_model(
        self,
        conceito: str,
        contexto: str,
        max_relacoes: int
    ) -> List[CandidatoRelacao]:
        """
        Extrai relaÃ§Ãµes usando o modelo local DeepSeek-Coder-V2-Lite.
        """
        if self.model is None or self.tokenizer is None:
            print("   âŒ Modelo nÃ£o carregado")
            return []
        
        prompt = self._build_extraction_prompt(conceito, contexto, max_relacoes)
        
        try:
            messages = [
                {
                    "role": "system",
                    "content": "VocÃª Ã© um extrator de conhecimento estrutural. "
                               "Identifique relaÃ§Ãµes explÃ­citas entre conceitos. "
                               "Retorne APENAS JSON vÃ¡lido, sem texto adicional."
                },
                {"role": "user", "content": prompt}
            ]
            
            inputs = self.tokenizer.apply_chat_template(
                messages,
                add_generation_prompt=True,
                return_tensors="pt"
            ).to(self.model.device)
            
            print("   ğŸ”„ Gerando extraÃ§Ã£o...")
            outputs = self.model.generate(
                inputs,
                max_new_tokens=2000,
                temperature=0.1,
                do_sample=True,
                top_p=0.95,
                pad_token_id=self.tokenizer.eos_token_id
            )
            
            raw_output = self.tokenizer.decode(
                outputs[0][inputs.shape[1]:],
                skip_special_tokens=True
            ).strip()
            
            return self._parse_api_response(raw_output, contexto)
            
        except Exception as e:
            print(f"   âŒ Erro na extraÃ§Ã£o: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _parse_api_response(self, raw: str, contexto: str) -> List[CandidatoRelacao]:
        """
        Parseia a resposta JSON da API.
        """
        try:
            # Remove markdown code blocks se presentes
            if raw.startswith("```"):
                raw = raw.split("```")[1]
                if raw.startswith("json"):
                    raw = raw[4:]
            
            data = json.loads(raw)
            candidatos = []
            
            for rel in data.get("relacoes", data if isinstance(data, list) else []):
                candidatos.append(CandidatoRelacao(
                    de=rel["de"],
                    para=rel["para"],
                    tipo=rel["tipo"],
                    confianca=float(rel.get("confianca", 0.7)),
                    contexto=contexto,
                    evidencia=rel.get("evidencia", ""),
                    timestamp=datetime.now().isoformat(),
                    origem="deepseek-api"
                ))
            
            return candidatos
            
        except json.JSONDecodeError as e:
            print(f"   âŒ Erro ao parsear JSON: {e}")
            print(f"   Raw response: {raw[:200]}...")
            return []
        except Exception as e:
            print(f"   âŒ Erro ao processar resposta: {e}")
            return []
    
    def _build_extraction_prompt(self, conceito: str, contexto: str, max_relacoes: int) -> str:
        """ConstrÃ³i prompt estruturado para extraÃ§Ã£o."""
        return f"""Analise o conceito "{conceito}" no campo "{contexto}".

Identifique relaÃ§Ãµes estruturais explÃ­citas com outros conceitos.

Tipos de relaÃ§Ã£o permitidos:
- definicao: X Ã© definido como Y
- parte_de: X Ã© parte de Y
- causa: X causa Y
- relacionado: X estÃ¡ relacionado a Y (genÃ©rico)
- exemplo: X Ã© exemplo de Y

Retorne JSON no formato:
[
  {{
    "de": "conceito_origem",
    "para": "conceito_destino",
    "tipo": "tipo_relacao",
    "confianca": 0.0-1.0,
    "evidencia": "texto que justifica a relaÃ§Ã£o"
  }}
]

CritÃ©rios:
1. APENAS relaÃ§Ãµes explÃ­citas e verificÃ¡veis
2. confianca = quÃ£o certo vocÃª estÃ¡ (0.0 a 1.0)
3. evidencia = citaÃ§Ã£o ou raciocÃ­nio
4. NO MÃXIMO {max_relacoes} relaÃ§Ãµes mais relevantes
5. SEM especulaÃ§Ã£o ou filosofia
6. SEM relaÃ§Ãµes Ã³bvias demais

Responda APENAS com o JSON, sem texto adicional."""
    
    def _extract_mock(self, conceito: str, contexto: str) -> List[CandidatoRelacao]:
        """Mock de extraÃ§Ã£o (fallback quando API nÃ£o disponÃ­vel)"""
        return [
            CandidatoRelacao(
                de=conceito,
                para="trabalho",
                tipo="definicao",
                confianca=0.95,
                contexto=contexto,
                evidencia="Energia Ã© a capacidade de realizar trabalho",
                timestamp=datetime.now().isoformat(),
                origem="mock"
            ),
            CandidatoRelacao(
                de=conceito,
                para="movimento",
                tipo="causa",
                confianca=0.85,
                contexto=contexto,
                evidencia="Energia pode causar movimento em sistemas fÃ­sicos",
                timestamp=datetime.now().isoformat(),
                origem="mock"
            )
        ]
    
    def _save_to_quarantine(self, conceito: str, candidatos: List[CandidatoRelacao]):
        """Salva candidatos na zona de quarentena para validaÃ§Ã£o humana."""
        quarantine_file = self.quarantine_path / f"quarentena_{conceito}.json"
        
        data = {
            "conceito_raiz": conceito,
            "timestamp": datetime.now().isoformat(),
            "total_candidatos": len(candidatos),
            "status": "aguardando_validacao",
            "candidatos": [
                {
                    "de": c.de,
                    "para": c.para,
                    "tipo": c.tipo,
                    "confianca": c.confianca,
                    "contexto": c.contexto,
                    "evidencia": c.evidencia,
                    "timestamp": c.timestamp,
                    "origem": c.origem,
                    "validado": False,
                    "acao": None  # aceitar|rejeitar|modificar
                }
                for c in candidatos
            ]
        }
        
        quarantine_file.write_text(
            json.dumps(data, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
        
        print(f"ğŸ’¾ {len(candidatos)} candidatos salvos em quarentena:")
        print(f"   {quarantine_file}")
    
    def list_quarantine(self) -> List[str]:
        """Lista arquivos na zona de quarentena."""
        if not self.quarantine_path.exists():
            return []
        return [f.name for f in self.quarantine_path.glob("quarentena_*.json")]
    
    def load_quarantine(self, conceito: str) -> Optional[Dict]:
        """Carrega candidatos da quarentena para validaÃ§Ã£o."""
        quarantine_file = self.quarantine_path / f"quarentena_{conceito}.json"
        if not quarantine_file.exists():
            return None
        return json.loads(quarantine_file.read_text(encoding="utf-8"))
    
    def validate_candidate(
        self,
        conceito: str,
        index: int,
        acao: str,
        modificacoes: Optional[Dict] = None
    ) -> bool:
        """
        Valida um candidato especÃ­fico.
        
        Args:
            conceito: Conceito raiz
            index: Ãndice do candidato
            acao: 'aceitar', 'rejeitar' ou 'modificar'
            modificacoes: Dict com campos modificados (se acao='modificar')
        
        Returns:
            True se validaÃ§Ã£o foi registrada
        """
        data = self.load_quarantine(conceito)
        if not data or index >= len(data["candidatos"]):
            return False
        
        data["candidatos"][index]["validado"] = True
        data["candidatos"][index]["acao"] = acao
        
        if acao == "modificar" and modificacoes:
            for k, v in modificacoes.items():
                if k in data["candidatos"][index]:
                    data["candidatos"][index][k] = v
        
        # Atualiza status
        total = len(data["candidatos"])
        validados = sum(1 for c in data["candidatos"] if c["validado"])
        data["status"] = f"validados_{validados}/{total}"
        
        quarantine_file = self.quarantine_path / f"quarentena_{conceito}.json"
        quarantine_file.write_text(
            json.dumps(data, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
        
        return True
    
    def export_validated(self, conceito: str) -> List[Dict]:
        """
        Exporta apenas candidatos aceitos para adiÃ§Ã£o ao grafo.
        
        Returns:
            Lista de relaÃ§Ãµes prontas para colapso no TRQ Graph
        """
        data = self.load_quarantine(conceito)
        if not data:
            return []
        
        aceitos = [
            {
                "de": c["de"],
                "para": c["para"],
                "tipo": c["tipo"],
                "peso": c["confianca"],
                "origem": "deepseek_validado"
            }
            for c in data["candidatos"]
            if c.get("validado") and c.get("acao") == "aceitar"
        ]
        
        return aceitos


# FunÃ§Ãµes helper para uso direto

def extrair_conhecimento(conceito: str, contexto: str = "geral") -> int:
    """
    Extrai candidatos de conhecimento para um conceito.
    Retorna nÃºmero de candidatos extraÃ­dos.
    """
    miner = KnowledgeMiner("data/quarentena")
    candidatos = miner.extract_candidates(conceito, contexto)
    print(f"\nğŸ”¬ MineraÃ§Ã£o estrutural concluÃ­da:")
    print(f"   Conceito: {conceito}")
    print(f"   Contexto: {contexto}")
    print(f"   Candidatos: {len(candidatos)}")
    print(f"\nâš ï¸  NADA foi adicionado ao grafo automaticamente.")
    print(f"   Use /validar para revisar os candidatos.")
    return len(candidatos)

def listar_quarentena() -> List[str]:
    """Lista todos os arquivos em quarentena."""
    miner = KnowledgeMiner("data/quarentena")
    return miner.list_quarantine()
